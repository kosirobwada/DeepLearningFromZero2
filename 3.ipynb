{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6WBNtgwyVLbP//HTTNzZz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kosirobwada/DeepLearningFromZero2/blob/main/3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 第3章　word2vec\n"
      ],
      "metadata": {
        "id": "29O4i2lEI1k9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# カウントベースの手法の問題点\n",
        "\n",
        "・現実的には、コーパスで扱う語彙数は非常に巨大になる。\n",
        "\n",
        "・すると、巨大な行列を作らなければならず、SVDを行うのが現実的でない。SVDは、O(N^3)"
      ],
      "metadata": {
        "id": "jSYD5fZ3LNI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 推論ベースの手法\n",
        "\n",
        "・ニューラルネットワークを用いる場合は、ミニバッチ学習をする。\n",
        "\n",
        "・ミニバッチ学習をするとは、一度に少量のミニバッチの学習サンプルを見ながら重み更新を繰り返す。\n",
        "\n",
        "・推論ベースの手法では、学習データの一部を使って逐次的に計算する。\n",
        "\n",
        "・これにより、計算量が膨大で処理が難しい場合でも、ニューラルネットワークでは処理を小分けにして実行できる。"
      ],
      "metadata": {
        "id": "7VfmlTSrNGm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# one-hot 表現\n",
        "\n",
        "・one-hot表現とは、ベクトルの要素の中でひとつだけが1で残りが0のベクトル。"
      ],
      "metadata": {
        "id": "PDwanmXEOeYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "c = np.array([[1,0,0,0,0,0,0]])\n",
        "W = np.random.randn(7,3)\n",
        "h = np.dot(c,W)\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKf54is8PDYU",
        "outputId": "f512528c-11ca-4764-cd23-446cb4af9ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.18300872  1.52038272  0.96223897]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MatMul:\n",
        "  def __init__(self,W):\n",
        "    self.params = [W]\n",
        "    self.grads = [np.zeros_like(W)]\n",
        "    self.x = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    W, = self.params\n",
        "    out = np.dot(x, W)\n",
        "    self.x = x\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    W, = self.params\n",
        "    dx = np.dot(dout, W.T)\n",
        "    dW = np.dot(self.x.T, dout)\n",
        "    self.grads[0][...] = dW\n",
        "    return dx\n",
        "\n",
        "c = np.array([[1,0,0,0,0,0,0]])\n",
        "W = np.random.randn(7,3)\n",
        "layer = MatMul(W)\n",
        "h = layer.forward(c)\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gOglITvPtuT",
        "outputId": "921c8138-0e9d-468d-a74d-836da18c5757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.14192312  0.65870819  1.16475768]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOW(Continuous Bag-Of-Words)\n",
        "\n",
        "・CBOWモデルは、コンテクストから、ターゲットを推測することを目的としたニューラルネットワークのモデル。\n",
        "\n",
        "・ターゲットは、中央の単語、その周辺の単語がコンテクスト\n",
        "\n",
        "・CBOWモデルをできるだけ正確な推測ができるように訓練することで、私たちは単語の分散表現を獲得することができる。\n",
        "\n",
        "・CBOWモデルへの入力は、単語のリスト。それをone-hot表現に変換することで、CBOWモデルが処理できるように調整する。\n",
        "\n",
        "・入力層としてN個の単語を扱うのであれば、N個の入力層が存在。"
      ],
      "metadata": {
        "id": "LejqsWgYRZas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c0 = np.array([[1,0,0,0,0,0,0]])\n",
        "c1 = np.array([[0,0,1,0,0,0,0]])\n",
        "\n",
        "W_in = np.random.randn(7,3)\n",
        "W_out = np.random.randn(3,7)\n",
        "\n",
        "in_layer0 = MatMul(W_in)\n",
        "in_layer1 = MatMul(W_in)\n",
        "out_layer = MatMul(W_out)\n",
        "\n",
        "h0 = in_layer0.forward(c0)\n",
        "h1 = in_layer1.forward(c1)\n",
        "h = 0.5 * (h0 + h1)\n",
        "s = out_layer.forward(h)\n",
        "\n",
        "print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykoPqSDzTtlo",
        "outputId": "b604967a-006d-4f32-a590-9499f40cbf91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.64544172 -0.08348532  0.16479746 -2.22382516  0.25740015  0.82392375\n",
            "   0.73392399]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CBOWモデルの学習\n",
        "\n",
        "・これまで見てきたCBOWモデルは、出力層ごとに各単語のスコアを出力してきた。\n",
        "\n",
        "・このスコアに対して、Softmax関数を適用することで、確率を得ることができる。\n",
        "\n",
        "・この確率は、コンテクストが与えられたときに、その中央にどの単語が出現するのかを表す。"
      ],
      "metadata": {
        "id": "6O6cprjFUjpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('.',' .')\n",
        "  words = text.split(' ')\n",
        "\n",
        "  word_to_id = {}\n",
        "  id_to_word = {}\n",
        "\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "      id_to_word[new_id] = word\n",
        "\n",
        "  corpus = np.array([word_to_id[w] for w in words])\n",
        "\n",
        "  return corpus, word_to_id, id_to_word\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "print(corpus)\n",
        "print(id_to_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzahqZIbl0Jl",
        "outputId": "ffff3543-8908-489f-b5ee-86c87a953f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 1 5 6]\n",
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_contexts_target(corpus, window_size=1):\n",
        "  target = corpus[window_size:-window_size]\n",
        "  contexts = []\n",
        "\n",
        "  for idx in range(window_size, len(corpus)-window_size):\n",
        "    cs = []\n",
        "    for t in range(-window_size, window_size+1):\n",
        "      if t==0:\n",
        "        continue\n",
        "      cs.append(corpus[idx+t])\n",
        "    contexts.append(cs)\n",
        "\n",
        "  return np.array(contexts), np.array(target)"
      ],
      "metadata": {
        "id": "1X_KORNBmdWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexts, target = create_contexts_target(corpus, window_size=1)\n",
        "print(contexts)\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nitD8-_WnL91",
        "outputId": "db183e59-cea8-4751-87bf-80fd9d25f99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 2]\n",
            " [1 3]\n",
            " [2 4]\n",
            " [3 1]\n",
            " [4 5]\n",
            " [1 6]]\n",
            "[1 2 3 4 1 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_one_hot(corpus, vocab_size):\n",
        "    N = corpus.shape[0]\n",
        "\n",
        "    if corpus.ndim == 1:\n",
        "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)\n",
        "\n",
        "        for idx, word_id in enumerate(corpus):\n",
        "            one_hot[idx, word_id] = 1\n",
        "\n",
        "    elif corpus.ndim == 2:\n",
        "        C = corpus.shape[1]\n",
        "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)\n",
        "        for idx_0, word_ids in enumerate(corpus):\n",
        "            for idx_1, word_id in enumerate(word_ids):\n",
        "                one_hot[idx_0, idx_1, word_id] = 1\n",
        "\n",
        "    return one_hot"
      ],
      "metadata": {
        "id": "B_Vab-sZpD29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "contexts, target = create_contexts_target(corpus, window_size=1)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "\n",
        "contexts = convert_one_hot(contexts, vocab_size)"
      ],
      "metadata": {
        "id": "Cpd6Onpwn27X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x - x.max(axis=1, keepdims=True)\n",
        "        x = np.exp(x)\n",
        "        x /= x.sum(axis=1, keepdims=True)\n",
        "    elif x.ndim == 1:\n",
        "        x = x - np.max(x)\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "\n",
        "    # if training data is one-hot-vector\n",
        "    # then convert to teaching label's index\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "\n",
        "    batch_size = y.shape[0]\n",
        "\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.y = None # output of softmax\n",
        "        self.t = None # teaching data label\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "\n",
        "        # if teaching data label is one-hot vector\n",
        "        # then convert to answer data index\n",
        "        if self.t.size == self.y.size:\n",
        "            self.t = self.t.argmax(axis=1)\n",
        "\n",
        "        loss = cross_entropy_error(self.y, self.t)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        dx = self.y.copy()\n",
        "        dx[np.arange(batch_size), self.t] -= 1\n",
        "        dx *= dout\n",
        "        dx = dx / batch_size\n",
        "\n",
        "        return dx\n",
        "\n"
      ],
      "metadata": {
        "id": "vouIHYKepLkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCBOW:\n",
        "  def __init__(self, vocab_size, hidden_size):\n",
        "    V ,H = vocab_size, hidden_size\n",
        "\n",
        "    W_in = 0.01 * np.random.randn(V,H).astype('f')\n",
        "    W_out = 0.01 * np.random.randn(H,V).astype('f')\n",
        "\n",
        "    self.in_layer0 = MatMul(W_in)\n",
        "    self.in_layer1 = MatMul(W_in)\n",
        "    self.out_layer = MatMul(W_out)\n",
        "    self.loss_layer = SoftmaxWithLoss()\n",
        "\n",
        "    layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
        "    self.params, self.grads = [],[]\n",
        "    for layer in layers:\n",
        "      self.params += layer.params\n",
        "      self.grads += layer.grads\n",
        "\n",
        "    self.word_vecs = W_in\n",
        "\n",
        "  def forward(self, contexts, target):\n",
        "    h0 = self.in_layer0.forward(contexts[:,0])\n",
        "    h1 = self.in_layer1.forward(contexts[:,1])\n",
        "    h = (h1 + h0) * 0.5\n",
        "    score = self.out_layer.forward(h)\n",
        "    loss = self.loss_layer.forward(score, target)\n",
        "    return loss\n",
        "\n",
        "  def backward(self, dout=1):\n",
        "    ds = self.loss_layer.backward(dout)\n",
        "    da = self.out_layer.backward(ds)\n",
        "    da *= 0.5\n",
        "    self.in_layer1.backward(da)\n",
        "    self.in_layer0.backward(da)\n",
        "    return None"
      ],
      "metadata": {
        "id": "eicE5YOXpiEr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, contexts, target):\n",
        "  h0 = self.in_layer0.forward(contexts[:,0])\n",
        "  h1 = self.in_layer1.forward(contexts[:,1])\n",
        "  h = (h1 + h0) * 0.5\n",
        "  score = self.out_layer.forward(h)\n",
        "  loss = self.loss_layer.forward(score, target)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "DdLyy2FvrDDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(self, dout=1):\n",
        "  ds = self.loss_layer.backward(dout)\n",
        "  da = self.out_layer.backward(ds)\n",
        "  da *= 0.5\n",
        "  self.in_layer1.backward(da)\n",
        "  self.in_layer0.backward(da)\n",
        "  return None"
      ],
      "metadata": {
        "id": "GWirxm4HrouU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def clip_grads(grads, max_norm):\n",
        "    total_norm = 0\n",
        "\n",
        "    for grad in grads:\n",
        "        total_norm += np.sum(grad ** 2)\n",
        "\n",
        "    total_norm = np.sqrt(total_norm)\n",
        "    rate = max_norm / (total_norm + 1e-6)\n",
        "\n",
        "    if rate < 1:\n",
        "        for grad in grads:\n",
        "            grad *= rate\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_list = []\n",
        "        self.eval_interval = None\n",
        "        self.current_epoch = 0\n",
        "\n",
        "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
        "        \"\"\"\n",
        "        train data\n",
        "        :param x: input data\n",
        "        :param t: teacher label\n",
        "        :param max_epoch: times of learning epoch\n",
        "        :param batch_size: sizes of min batch\n",
        "        :param max_grad: max norm of grad. if norm of grads is over this value, decline grad\n",
        "                        (grad clipping: see chapter 05 for more detail)\n",
        "        :param eval_interval: print results interval\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        data_size = len(x)\n",
        "        max_iters = data_size // batch_size\n",
        "        self.eval_interval = eval_interval\n",
        "        model, optimizer = self.model, self.optimizer\n",
        "        total_loss = 0\n",
        "        loss_count = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for epoch in range(max_epoch):\n",
        "            # shuffle\n",
        "            idx = numpy.random.permutation(numpy.arange(data_size))\n",
        "            x = x[idx]\n",
        "            t = t[idx]\n",
        "\n",
        "            for iters in range(max_iters):\n",
        "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "                # calculate grad and update parameters\n",
        "                loss = model.forward(batch_x, batch_t)\n",
        "                model.backward()\n",
        "                params, grads = remove_duplicate(model.params, model.grads)\n",
        "\n",
        "                if max_grad is not None:\n",
        "                    clip_grads(grads, max_grad)\n",
        "\n",
        "                optimizer.update(params, grads)\n",
        "                total_loss += loss\n",
        "                loss_count += 1\n",
        "\n",
        "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
        "                    avg_loss = total_loss / loss_count\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    print('| epoch %d | iter %d / %d | time %d[s] | loss %.2f'\n",
        "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
        "                    self.loss_list.append(float(avg_loss))\n",
        "                    total_loss, loss_count = 0, 0\n",
        "\n",
        "            self.current_epoch += 1\n",
        "\n",
        "    def plot(self, ylim=None):\n",
        "        \"\"\"\n",
        "        plotting data\n",
        "        :param ylim: display range of y axis\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        x = numpy.arange(len(self.loss_list))\n",
        "\n",
        "        if ylim is not None:\n",
        "            plt.ylim(*ylim)\n",
        "\n",
        "        plt.plot(x, self.loss_list, label='train')\n",
        "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
        "        plt.ylabel('loss')\n",
        "        plt.show()\n",
        "\n",
        "def remove_duplicate(params, grads):\n",
        "    \"\"\"\n",
        "    remove duplicate at parameters array\n",
        "    and adds grad\n",
        "    :param params:\n",
        "    :param grads:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    params, grads = params[:], grads[:] # copy list\n",
        "\n",
        "    while True:\n",
        "        find_flg = False\n",
        "        L = len(params)\n",
        "\n",
        "        for i in range(0, L - 1):\n",
        "            for j in range(i + 1, L):\n",
        "                # in case weight sharing\n",
        "                if params[i] is params[j]:\n",
        "                    grads[i] += grads[j]\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "                # in case weight tying\n",
        "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
        "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
        "                    grads[i] += grads[j].T\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "\n",
        "                if find_flg: break\n",
        "            if find_flg: break\n",
        "        if not find_flg: break\n",
        "\n",
        "    return params, grads\n",
        "\n"
      ],
      "metadata": {
        "id": "k6NK52QpxmfN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Adam:\n",
        "    \"\"\"\n",
        "    Adam (http://arxiv.org/abs/1412.6980v8)\n",
        "    \"\"\"\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "\n",
        "    def update(self, params, grads):\n",
        "        if self.m is None:\n",
        "            self.m, self.v = [], []\n",
        "\n",
        "            for param in params:\n",
        "                self.m.append(np.zeros_like(param))\n",
        "                self.v.append(np.zeros_like(param))\n",
        "\n",
        "        self.iter += 1\n",
        "        lr_t = self.lr * np.sqrt(1.0 - self.beta2 ** self.iter) / (1.0 - self.beta1 ** self.iter)\n",
        "\n",
        "        for i in range(len(params)):\n",
        "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
        "            self.v[i] += (1 - self.beta2) * (grads[i] ** 2 - self.v[i])\n",
        "\n",
        "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
      ],
      "metadata": {
        "id": "7W03hiCaxzhG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 1\n",
        "hidden_size = 5\n",
        "batch_size = 3\n",
        "max_epoch = 1000\n",
        "\n",
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "contexts, target = create_contexts_target(corpus, window_size)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "contexts = convert_one_hot(contexts, vocab_size)\n",
        "\n",
        "model = SimpleCBOW(vocab_size, hidden_size)\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "trainer.fit(contexts, target, max_epoch, batch_size)\n",
        "trainer.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ocgAhLoWsPCs",
        "outputId": "3b486ea3-3ca3-4c68-e6d3-6d1bd474bb4d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch 1 | iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 2 | iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 3 | iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 4 | iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 5 | iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 6 | iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 7 | iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 8 | iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 9 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 10 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 11 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 12 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 13 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 14 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 15 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 16 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 17 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 18 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 19 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 20 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 21 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 22 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 23 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 24 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 25 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 26 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 27 | iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 28 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 29 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 30 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 31 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 32 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 33 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 34 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 35 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 36 | iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 37 | iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 38 | iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 39 | iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 40 | iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 41 | iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 42 | iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 43 | iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 44 | iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 45 | iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 46 | iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 47 | iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 48 | iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 49 | iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 50 | iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 51 | iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 52 | iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 53 | iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 54 | iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 55 | iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 56 | iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 57 | iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 58 | iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 59 | iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 60 | iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 61 | iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 62 | iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 63 | iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 64 | iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 65 | iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 66 | iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 67 | iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 68 | iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 69 | iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 70 | iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 71 | iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 72 | iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 73 | iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 74 | iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 75 | iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 76 | iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 77 | iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 78 | iter 1 / 2 | time 0[s] | loss 1.81\n",
            "| epoch 79 | iter 1 / 2 | time 0[s] | loss 1.80\n",
            "| epoch 80 | iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 81 | iter 1 / 2 | time 0[s] | loss 1.80\n",
            "| epoch 82 | iter 1 / 2 | time 0[s] | loss 1.80\n",
            "| epoch 83 | iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 84 | iter 1 / 2 | time 0[s] | loss 1.80\n",
            "| epoch 85 | iter 1 / 2 | time 0[s] | loss 1.78\n",
            "| epoch 86 | iter 1 / 2 | time 0[s] | loss 1.78\n",
            "| epoch 87 | iter 1 / 2 | time 0[s] | loss 1.78\n",
            "| epoch 88 | iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 89 | iter 1 / 2 | time 0[s] | loss 1.78\n",
            "| epoch 90 | iter 1 / 2 | time 0[s] | loss 1.76\n",
            "| epoch 91 | iter 1 / 2 | time 0[s] | loss 1.75\n",
            "| epoch 92 | iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 93 | iter 1 / 2 | time 0[s] | loss 1.73\n",
            "| epoch 94 | iter 1 / 2 | time 0[s] | loss 1.75\n",
            "| epoch 95 | iter 1 / 2 | time 0[s] | loss 1.76\n",
            "| epoch 96 | iter 1 / 2 | time 0[s] | loss 1.74\n",
            "| epoch 97 | iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 98 | iter 1 / 2 | time 0[s] | loss 1.73\n",
            "| epoch 99 | iter 1 / 2 | time 0[s] | loss 1.75\n",
            "| epoch 100 | iter 1 / 2 | time 0[s] | loss 1.70\n",
            "| epoch 101 | iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 102 | iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 103 | iter 1 / 2 | time 0[s] | loss 1.71\n",
            "| epoch 104 | iter 1 / 2 | time 0[s] | loss 1.68\n",
            "| epoch 105 | iter 1 / 2 | time 0[s] | loss 1.71\n",
            "| epoch 106 | iter 1 / 2 | time 0[s] | loss 1.71\n",
            "| epoch 107 | iter 1 / 2 | time 0[s] | loss 1.69\n",
            "| epoch 108 | iter 1 / 2 | time 0[s] | loss 1.66\n",
            "| epoch 109 | iter 1 / 2 | time 0[s] | loss 1.69\n",
            "| epoch 110 | iter 1 / 2 | time 0[s] | loss 1.68\n",
            "| epoch 111 | iter 1 / 2 | time 0[s] | loss 1.69\n",
            "| epoch 112 | iter 1 / 2 | time 0[s] | loss 1.66\n",
            "| epoch 113 | iter 1 / 2 | time 0[s] | loss 1.66\n",
            "| epoch 114 | iter 1 / 2 | time 0[s] | loss 1.67\n",
            "| epoch 115 | iter 1 / 2 | time 0[s] | loss 1.65\n",
            "| epoch 116 | iter 1 / 2 | time 0[s] | loss 1.65\n",
            "| epoch 117 | iter 1 / 2 | time 0[s] | loss 1.64\n",
            "| epoch 118 | iter 1 / 2 | time 0[s] | loss 1.62\n",
            "| epoch 119 | iter 1 / 2 | time 0[s] | loss 1.66\n",
            "| epoch 120 | iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 121 | iter 1 / 2 | time 0[s] | loss 1.62\n",
            "| epoch 122 | iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 123 | iter 1 / 2 | time 0[s] | loss 1.60\n",
            "| epoch 124 | iter 1 / 2 | time 0[s] | loss 1.61\n",
            "| epoch 125 | iter 1 / 2 | time 0[s] | loss 1.62\n",
            "| epoch 126 | iter 1 / 2 | time 0[s] | loss 1.59\n",
            "| epoch 127 | iter 1 / 2 | time 0[s] | loss 1.59\n",
            "| epoch 128 | iter 1 / 2 | time 0[s] | loss 1.59\n",
            "| epoch 129 | iter 1 / 2 | time 0[s] | loss 1.62\n",
            "| epoch 130 | iter 1 / 2 | time 0[s] | loss 1.55\n",
            "| epoch 131 | iter 1 / 2 | time 0[s] | loss 1.58\n",
            "| epoch 132 | iter 1 / 2 | time 0[s] | loss 1.59\n",
            "| epoch 133 | iter 1 / 2 | time 0[s] | loss 1.58\n",
            "| epoch 134 | iter 1 / 2 | time 0[s] | loss 1.53\n",
            "| epoch 135 | iter 1 / 2 | time 0[s] | loss 1.57\n",
            "| epoch 136 | iter 1 / 2 | time 0[s] | loss 1.57\n",
            "| epoch 137 | iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 138 | iter 1 / 2 | time 0[s] | loss 1.56\n",
            "| epoch 139 | iter 1 / 2 | time 0[s] | loss 1.54\n",
            "| epoch 140 | iter 1 / 2 | time 0[s] | loss 1.56\n",
            "| epoch 141 | iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 142 | iter 1 / 2 | time 0[s] | loss 1.53\n",
            "| epoch 143 | iter 1 / 2 | time 0[s] | loss 1.50\n",
            "| epoch 144 | iter 1 / 2 | time 0[s] | loss 1.55\n",
            "| epoch 145 | iter 1 / 2 | time 0[s] | loss 1.48\n",
            "| epoch 146 | iter 1 / 2 | time 0[s] | loss 1.50\n",
            "| epoch 147 | iter 1 / 2 | time 0[s] | loss 1.54\n",
            "| epoch 148 | iter 1 / 2 | time 0[s] | loss 1.47\n",
            "| epoch 149 | iter 1 / 2 | time 0[s] | loss 1.50\n",
            "| epoch 150 | iter 1 / 2 | time 0[s] | loss 1.44\n",
            "| epoch 151 | iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 152 | iter 1 / 2 | time 0[s] | loss 1.48\n",
            "| epoch 153 | iter 1 / 2 | time 0[s] | loss 1.49\n",
            "| epoch 154 | iter 1 / 2 | time 0[s] | loss 1.44\n",
            "| epoch 155 | iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 156 | iter 1 / 2 | time 0[s] | loss 1.49\n",
            "| epoch 157 | iter 1 / 2 | time 0[s] | loss 1.43\n",
            "| epoch 158 | iter 1 / 2 | time 0[s] | loss 1.45\n",
            "| epoch 159 | iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 160 | iter 1 / 2 | time 0[s] | loss 1.44\n",
            "| epoch 161 | iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 162 | iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 163 | iter 1 / 2 | time 0[s] | loss 1.45\n",
            "| epoch 164 | iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 165 | iter 1 / 2 | time 0[s] | loss 1.42\n",
            "| epoch 166 | iter 1 / 2 | time 0[s] | loss 1.42\n",
            "| epoch 167 | iter 1 / 2 | time 0[s] | loss 1.43\n",
            "| epoch 168 | iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 169 | iter 1 / 2 | time 0[s] | loss 1.36\n",
            "| epoch 170 | iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 171 | iter 1 / 2 | time 0[s] | loss 1.39\n",
            "| epoch 172 | iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 173 | iter 1 / 2 | time 0[s] | loss 1.38\n",
            "| epoch 174 | iter 1 / 2 | time 0[s] | loss 1.44\n",
            "| epoch 175 | iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 176 | iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 177 | iter 1 / 2 | time 0[s] | loss 1.37\n",
            "| epoch 178 | iter 1 / 2 | time 0[s] | loss 1.36\n",
            "| epoch 179 | iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 180 | iter 1 / 2 | time 0[s] | loss 1.43\n",
            "| epoch 181 | iter 1 / 2 | time 0[s] | loss 1.28\n",
            "| epoch 182 | iter 1 / 2 | time 0[s] | loss 1.42\n",
            "| epoch 183 | iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 184 | iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 185 | iter 1 / 2 | time 0[s] | loss 1.37\n",
            "| epoch 186 | iter 1 / 2 | time 0[s] | loss 1.30\n",
            "| epoch 187 | iter 1 / 2 | time 0[s] | loss 1.31\n",
            "| epoch 188 | iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 189 | iter 1 / 2 | time 0[s] | loss 1.34\n",
            "| epoch 190 | iter 1 / 2 | time 0[s] | loss 1.37\n",
            "| epoch 191 | iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 192 | iter 1 / 2 | time 0[s] | loss 1.31\n",
            "| epoch 193 | iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 194 | iter 1 / 2 | time 0[s] | loss 1.32\n",
            "| epoch 195 | iter 1 / 2 | time 0[s] | loss 1.30\n",
            "| epoch 196 | iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 197 | iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 198 | iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 199 | iter 1 / 2 | time 0[s] | loss 1.28\n",
            "| epoch 200 | iter 1 / 2 | time 0[s] | loss 1.28\n",
            "| epoch 201 | iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 202 | iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 203 | iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 204 | iter 1 / 2 | time 0[s] | loss 1.30\n",
            "| epoch 205 | iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 206 | iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 207 | iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 208 | iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 209 | iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 210 | iter 1 / 2 | time 0[s] | loss 1.24\n",
            "| epoch 211 | iter 1 / 2 | time 0[s] | loss 1.24\n",
            "| epoch 212 | iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 213 | iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 214 | iter 1 / 2 | time 0[s] | loss 1.27\n",
            "| epoch 215 | iter 1 / 2 | time 0[s] | loss 1.32\n",
            "| epoch 216 | iter 1 / 2 | time 0[s] | loss 1.09\n",
            "| epoch 217 | iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 218 | iter 1 / 2 | time 0[s] | loss 1.22\n",
            "| epoch 219 | iter 1 / 2 | time 0[s] | loss 1.31\n",
            "| epoch 220 | iter 1 / 2 | time 0[s] | loss 1.21\n",
            "| epoch 221 | iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 222 | iter 1 / 2 | time 0[s] | loss 1.13\n",
            "| epoch 223 | iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 224 | iter 1 / 2 | time 0[s] | loss 1.30\n",
            "| epoch 225 | iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 226 | iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 227 | iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 228 | iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 229 | iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 230 | iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 231 | iter 1 / 2 | time 0[s] | loss 1.13\n",
            "| epoch 232 | iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 233 | iter 1 / 2 | time 0[s] | loss 1.22\n",
            "| epoch 234 | iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 235 | iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 236 | iter 1 / 2 | time 0[s] | loss 1.09\n",
            "| epoch 237 | iter 1 / 2 | time 0[s] | loss 1.21\n",
            "| epoch 238 | iter 1 / 2 | time 0[s] | loss 1.11\n",
            "| epoch 239 | iter 1 / 2 | time 0[s] | loss 1.21\n",
            "| epoch 240 | iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 241 | iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 242 | iter 1 / 2 | time 0[s] | loss 1.31\n",
            "| epoch 243 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 244 | iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 245 | iter 1 / 2 | time 0[s] | loss 1.09\n",
            "| epoch 246 | iter 1 / 2 | time 0[s] | loss 1.11\n",
            "| epoch 247 | iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 248 | iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 249 | iter 1 / 2 | time 0[s] | loss 1.13\n",
            "| epoch 250 | iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 251 | iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 252 | iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 253 | iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 254 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 255 | iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 256 | iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 257 | iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 258 | iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 259 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 260 | iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 261 | iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 262 | iter 1 / 2 | time 0[s] | loss 1.22\n",
            "| epoch 263 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 264 | iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 265 | iter 1 / 2 | time 0[s] | loss 1.13\n",
            "| epoch 266 | iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 267 | iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 268 | iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 269 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 270 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 271 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 272 | iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 273 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 274 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 275 | iter 1 / 2 | time 0[s] | loss 1.23\n",
            "| epoch 276 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 277 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 278 | iter 1 / 2 | time 0[s] | loss 1.13\n",
            "| epoch 279 | iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 280 | iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 281 | iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 282 | iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 283 | iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 284 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 285 | iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 286 | iter 1 / 2 | time 0[s] | loss 1.02\n",
            "| epoch 287 | iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 288 | iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 289 | iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 290 | iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 291 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 292 | iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 293 | iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 294 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 295 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 296 | iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 297 | iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 298 | iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 299 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 300 | iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 301 | iter 1 / 2 | time 0[s] | loss 1.13\n",
            "| epoch 302 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 303 | iter 1 / 2 | time 0[s] | loss 1.09\n",
            "| epoch 304 | iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 305 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 306 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 307 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 308 | iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 309 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 310 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 311 | iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 312 | iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 313 | iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 314 | iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 315 | iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 316 | iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 317 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 318 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 319 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 320 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 321 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 322 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 323 | iter 1 / 2 | time 0[s] | loss 1.02\n",
            "| epoch 324 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 325 | iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 326 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 327 | iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 328 | iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 329 | iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 330 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 331 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 332 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 333 | iter 1 / 2 | time 0[s] | loss 1.13\n",
            "| epoch 334 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 335 | iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 336 | iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 337 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 338 | iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 339 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 340 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 341 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 342 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 343 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 344 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 345 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 346 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 347 | iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 348 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 349 | iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 350 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 351 | iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 352 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 353 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 354 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 355 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 356 | iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 357 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 358 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 359 | iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 360 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 361 | iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 362 | iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 363 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 364 | iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 365 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 366 | iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 367 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 368 | iter 1 / 2 | time 0[s] | loss 1.11\n",
            "| epoch 369 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 370 | iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 371 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 372 | iter 1 / 2 | time 0[s] | loss 1.11\n",
            "| epoch 373 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 374 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 375 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 376 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 377 | iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 378 | iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 379 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 380 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 381 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 382 | iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 383 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 384 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 385 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 386 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 387 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 388 | iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 389 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 390 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 391 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 392 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 393 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 394 | iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 395 | iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 396 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 397 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 398 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 399 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 400 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 401 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 402 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 403 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 404 | iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 405 | iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 406 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 407 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 408 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 409 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 410 | iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 411 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 412 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 413 | iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 414 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 415 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 416 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 417 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 418 | iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 419 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 420 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 421 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 422 | iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 423 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 424 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 425 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 426 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 427 | iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 428 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 429 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 430 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 431 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 432 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 433 | iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 434 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 435 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 436 | iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 437 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 438 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 439 | iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 440 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 441 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 442 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 443 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 444 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 445 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 446 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 447 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 448 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 449 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 450 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 451 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 452 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 453 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 454 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 455 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 456 | iter 1 / 2 | time 0[s] | loss 1.11\n",
            "| epoch 457 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 458 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 459 | iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 460 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 461 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 462 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 463 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 464 | iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 465 | iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 466 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 467 | iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 468 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 469 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 470 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 471 | iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 472 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 473 | iter 1 / 2 | time 0[s] | loss 1.02\n",
            "| epoch 474 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 475 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 476 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 477 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 478 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 479 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 480 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 481 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 482 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 483 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 484 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 485 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 486 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 487 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 488 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 489 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 490 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 491 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 492 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 493 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 494 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 495 | iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 496 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 497 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 498 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 499 | iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 500 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 501 | iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 502 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 503 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 504 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 505 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 506 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 507 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 508 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 509 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 510 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 511 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 512 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 513 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 514 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 515 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 516 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 517 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 518 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 519 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 520 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 521 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 522 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 523 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 524 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 525 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 526 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 527 | iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 528 | iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 529 | iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 530 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 531 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 532 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 533 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 534 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 535 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 536 | iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 537 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 538 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 539 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 540 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 541 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 542 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 543 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 544 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 545 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 546 | iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 547 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 548 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 549 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 550 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 551 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 552 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 553 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 554 | iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 555 | iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 556 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 557 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 558 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 559 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 560 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 561 | iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 562 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 563 | iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 564 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 565 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 566 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 567 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 568 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 569 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 570 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 571 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 572 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 573 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 574 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 575 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 576 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 577 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 578 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 579 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 580 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 581 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 582 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 583 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 584 | iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 585 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 586 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 587 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 588 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 589 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 590 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 591 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 592 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 593 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 594 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 595 | iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 596 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 597 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 598 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 599 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 600 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 601 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 602 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 603 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 604 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 605 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 606 | iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 607 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 608 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 609 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 610 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 611 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 612 | iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 613 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 614 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 615 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 616 | iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 617 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 618 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 619 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 620 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 621 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 622 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 623 | iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 624 | iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 625 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 626 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 627 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 628 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 629 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 630 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 631 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 632 | iter 1 / 2 | time 0[s] | loss 1.02\n",
            "| epoch 633 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 634 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 635 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 636 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 637 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 638 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 639 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 640 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 641 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 642 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 643 | iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 644 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 645 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 646 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 647 | iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 648 | iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 649 | iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 650 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 651 | iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 652 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 653 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 654 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 655 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 656 | iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 657 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 658 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 659 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 660 | iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 661 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 662 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 663 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 664 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 665 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 666 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 667 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 668 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 669 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 670 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 671 | iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 672 | iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 673 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 674 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 675 | iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 676 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 677 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 678 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 679 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 680 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 681 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 682 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 683 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 684 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 685 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 686 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 687 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 688 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 689 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 690 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 691 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 692 | iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 693 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 694 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 695 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 696 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 697 | iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 698 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 699 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 700 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 701 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 702 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 703 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 704 | iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 705 | iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 706 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 707 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 708 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 709 | iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 710 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 711 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 712 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 713 | iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 714 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 715 | iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 716 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 717 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 718 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 719 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 720 | iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 721 | iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 722 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 723 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 724 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 725 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 726 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 727 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 728 | iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 729 | iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 730 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 731 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 732 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 733 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 734 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 735 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 736 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 737 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 738 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 739 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 740 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 741 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 742 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 743 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 744 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 745 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 746 | iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 747 | iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 748 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 749 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 750 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 751 | iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 752 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 753 | iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 754 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 755 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 756 | iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 757 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 758 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 759 | iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 760 | iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 761 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 762 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 763 | iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 764 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 765 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 766 | iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 767 | iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 768 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 769 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 770 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 771 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 772 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 773 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 774 | iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 775 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 776 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 777 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 778 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 779 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 780 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 781 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 782 | iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 783 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 784 | iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 785 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 786 | iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 787 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 788 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 789 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 790 | iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 791 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 792 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 793 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 794 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 795 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 796 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 797 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 798 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 799 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 800 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 801 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 802 | iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 803 | iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 804 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 805 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 806 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 807 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 808 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 809 | iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 810 | iter 1 / 2 | time 0[s] | loss 0.34\n",
            "| epoch 811 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 812 | iter 1 / 2 | time 0[s] | loss 0.32\n",
            "| epoch 813 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 814 | iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 815 | iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 816 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 817 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 818 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 819 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 820 | iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 821 | iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 822 | iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 823 | iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 824 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 825 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 826 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 827 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 828 | iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 829 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 830 | iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 831 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 832 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 833 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 834 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 835 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 836 | iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 837 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 838 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 839 | iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 840 | iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 841 | iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 842 | iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 843 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 844 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 845 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 846 | iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 847 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 848 | iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 849 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 850 | iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 851 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 852 | iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 853 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 854 | iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 855 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 856 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 857 | iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 858 | iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 859 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 860 | iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 861 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 862 | iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 863 | iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 864 | iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 865 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 866 | iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 867 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 868 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 869 | iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 870 | iter 1 / 2 | time 0[s] | loss 0.29\n",
            "| epoch 871 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 872 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 873 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 874 | iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 875 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 876 | iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 877 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 878 | iter 1 / 2 | time 0[s] | loss 0.29\n",
            "| epoch 879 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 880 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 881 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 882 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 883 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 884 | iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 885 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 886 | iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 887 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 888 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 889 | iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 890 | iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 891 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 892 | iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 893 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 894 | iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 895 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 896 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 897 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 898 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 899 | iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 900 | iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 901 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 902 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 903 | iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 904 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 905 | iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 906 | iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 907 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 908 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 909 | iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 910 | iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 911 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 912 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 913 | iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 914 | iter 1 / 2 | time 0[s] | loss 0.29\n",
            "| epoch 915 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 916 | iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 917 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 918 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 919 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 920 | iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 921 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 922 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 923 | iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 924 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 925 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 926 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 927 | iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 928 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 929 | iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 930 | iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 931 | iter 1 / 2 | time 0[s] | loss 0.27\n",
            "| epoch 932 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 933 | iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 934 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 935 | iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 936 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 937 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 938 | iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 939 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 940 | iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 941 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 942 | iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 943 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 944 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 945 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 946 | iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 947 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 948 | iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 949 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 950 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 951 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 952 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 953 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 954 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 955 | iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 956 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 957 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 958 | iter 1 / 2 | time 0[s] | loss 0.26\n",
            "| epoch 959 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 960 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 961 | iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 962 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 963 | iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 964 | iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 965 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 966 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 967 | iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 968 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 969 | iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 970 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 971 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 972 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 973 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 974 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 975 | iter 1 / 2 | time 0[s] | loss 0.25\n",
            "| epoch 976 | iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 977 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 978 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 979 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 980 | iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 981 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 982 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 983 | iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 984 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 985 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 986 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 987 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 988 | iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 989 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 990 | iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 991 | iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 992 | iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 993 | iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 994 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 995 | iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 996 | iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 997 | iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 998 | iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 999 | iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 1000 | iter 1 / 2 | time 0[s] | loss 0.65\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_vecs = model.word_vecs\n",
        "for word_id, word in id_to_word.items():\n",
        "  print(word, word_vecs[word_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS55S76JylnK",
        "outputId": "9e1c0ba9-bf69-4df2-937d-1a8aea2324da"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you [ 1.0136161 -1.0330466 -1.0292928 -1.6887484  1.0260006]\n",
            "say [-1.113763   1.0926903  1.1191225  1.3433295 -1.1823403]\n",
            "goodbye [ 0.9823285  -1.0129724  -0.9750915   0.72044724  0.9741136 ]\n",
            "and [-1.4334636   1.4866273   1.3812093   0.13747354 -1.1992091 ]\n",
            "i [ 0.96409297 -0.9952217  -0.9789082   0.710729    0.9682905 ]\n",
            "hello [ 1.0279342 -1.0312916 -1.0494803 -1.682684   0.9975571]\n",
            ". [-0.04207537 -0.12029526  0.14242621  1.6027398  -0.7034998 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3章のまとめ\n",
        "\n",
        "・推論ベースの手法では、推測することを目標として、その副産物としての単語の分散表現を得る。\n",
        "\n",
        "・word2vecは推論ベースの手法であり、シンプルな2層のニューラルネットワークで構成されている。\n",
        "\n",
        "・word2vecには、CBOWモデルとskip-gramモデルがある。\n",
        "\n",
        "・CBOWモデルは、複数の単語（コンテクスト）から、ひとつの単語（ターゲット）を推測する。\n",
        "\n",
        "・skip-gramモデルでは、逆に、ひとつの単語（ターゲット）から、複数の単語を予測する。\n",
        "\n",
        "・word2vecは、重みの再学習ができるため、単語の分散表現の更新や、追加が効率的に行える。"
      ],
      "metadata": {
        "id": "2Xdo0DTW0LvQ"
      }
    }
  ]
}